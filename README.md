# ğŸ­ The Empathy Engine â€” Giving AI a Human Voice

A Python service that **dynamically modulates vocal characteristics** of synthesized speech based on the **detected emotion** of the source text. Moving beyond monotonic TTS delivery to achieve expressive, human-like audio output.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Features](#features)
- [Setup & Installation](#setup--installation)
- [Usage](#usage)
  - [CLI](#cli)
  - [Web Interface](#web-interface)
- [Emotion-to-Voice Mapping](#emotion-to-voice-mapping)
- [Design Choices](#design-choices)
- [Project Structure](#project-structure)
- [Tech Stack](#tech-stack)

---

## Overview

Standard Text-to-Speech systems produce functional but robotic output â€” they lack prosody, emotional range, and the subtle vocal cues that build rapport. **The Empathy Engine** bridges this gap by:

1. **Detecting emotion** from input text using dual-engine analysis (VADER + HuggingFace transformers)
2. **Mapping emotions** to vocal parameter adjustments with intensity-aware scaling
3. **Synthesizing speech** with modulated rate, pitch, and volume to sound genuinely expressive

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE EMPATHY ENGINE                    â”‚
â”‚                                                         â”‚
â”‚  Input Text                                             â”‚
â”‚      â”‚                                                  â”‚
â”‚      â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  â”‚  EMOTION DETECTOR    â”‚                               â”‚
â”‚  â”‚  â”œâ”€ VADER Sentiment  â”‚â”€â”€â–º Compound Score â”€â”€â–º Intensityâ”‚
â”‚  â”‚  â””â”€ HuggingFace      â”‚â”€â”€â–º 7 Emotion Labels          â”‚
â”‚  â”‚     DistilRoBERTa    â”‚                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚             â”‚                                           â”‚
â”‚             â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  â”‚  VOICE MAPPER        â”‚                               â”‚
â”‚  â”‚  emotion + intensity â”‚â”€â”€â–º VoiceParams(rate, pitch,   â”‚
â”‚  â”‚  â†’ linear scaling    â”‚                    volume)    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚             â”‚                                           â”‚
â”‚             â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  â”‚  TTS ENGINE          â”‚                               â”‚
â”‚  â”‚  â”œâ”€ pyttsx3 (offline)â”‚â”€â”€â–º .wav audio file            â”‚
â”‚  â”‚  â””â”€ gTTS   (online)  â”‚â”€â”€â–º .mp3 audio file            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Features

### âœ… Core (Must-Haves)

| # | Requirement | Implementation |
|---|-------------|---------------|
| 1 | **Text Input** | CLI prompt + Flask API endpoint |
| 2 | **Emotion Detection** | 7 categories: joy, sadness, anger, surprise, fear, disgust, neutral |
| 3 | **Vocal Parameter Modulation** | Rate (wpm), Pitch (multiplier), Volume (0â€“1) |
| 4 | **Emotion-to-Voice Mapping** | Documented, demonstrable mapping table with clear logic |
| 5 | **Audio Output** | Generates playable `.wav` / `.mp3` files |

### ğŸŒŸ Bonus (Stretch Goals)

| Feature | Implementation |
|---------|---------------|
| **Granular Emotions** | 7+ emotions via HuggingFace `j-hartmann/emotion-english-distilroberta-base` |
| **Intensity Scaling** | All vocal adjustments scale linearly with emotion intensity (0.0â€“1.0) |
| **Web Interface** | Flask app with text input, emotion visualization, and embedded audio player |
| **SSML-Ready Architecture** | Modular design ready for SSML integration |

---

## Setup & Installation

### Prerequisites

- **Python 3.9+**
- **pip** (Python package manager)
- **ffmpeg** (optional, only needed for gTTS post-processing with pydub)

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/YOUR_USERNAME/empathy-engine.git
cd empathy-engine

# 2. Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate    # macOS/Linux
# venv\Scripts\activate     # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Download NLTK data (for VADER)
python -c "import nltk; nltk.download('vader_lexicon')"
```

> **Note:** The HuggingFace model (~300 MB) will be downloaded automatically on first run. Use `--no-hf` flag to skip this and use VADER-only mode for faster startup.

---

## Usage

### CLI

```bash
# Basic usage â€” positive emotion
python cli.py "I'm so excited about this new opportunity!"

# Negative emotion with custom output file
python cli.py "This is really frustrating and disappointing." --output frustrated.wav

# Use gTTS (online) instead of pyttsx3
python cli.py "Hello, how are you today?" --engine gtts

# Fast mode â€” VADER only, no HuggingFace model
python cli.py "Great job everyone!" --no-hf
```

**CLI Output Example:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         ğŸ­  THE EMPATHY ENGINE  ğŸ­                  â•‘
â•‘      Giving AI a Human Voice                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Input Text:
   "I'm so excited about this new opportunity!"

ğŸ” Emotion Analysis:
   Primary Emotion: JOY
   Granular Label:  joy
   Intensity:       [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 82.3%

ğŸ¤ Voice Parameters:
   Rate:   249 wpm
   Pitch:  1.29Ã—
   Volume: 0.97

ğŸ”Š Audio Output:
   /path/to/output/empathy_a1b2c3d4.wav
```

### Web Interface

```bash
# Start the Flask server
python web/app.py

# Open in browser
# http://localhost:5000
```

The web interface provides:
- ğŸ“ Text area for input
- ğŸ¤ "Speak with Emotion" button
- ğŸ” Emotion analysis with visual breakdown (emotion badge, intensity bar, score chart)
- ğŸ¤ Voice parameter display (rate, pitch, volume with baseline comparison)
- ğŸ”Š Embedded audio player for instant playback

---

## Emotion-to-Voice Mapping

The mapping logic is the heart of the Empathy Engine. Each emotion has a **profile** defining maximum adjustments for rate, pitch, and volume. These are **linearly scaled** by the detected intensity.

### Mapping Table (at maximum intensity)

| Emotion | Rate (wpm) | Pitch | Volume | Rationale |
|---------|-----------|-------|--------|-----------|
| ğŸ˜Š **Joy** | 260 (+30%) | 1.35Ã— | 1.00 | Happy speech is faster, higher-pitched, and louder |
| ğŸ˜¢ **Sadness** | 150 (-25%) | 0.78Ã— | 0.70 | Sad speech is slow, low-pitched, and quiet |
| ğŸ˜  **Anger** | 240 (+20%) | 1.22Ã— | 1.00 | Angry speech is forceful â€” faster, higher, and louder |
| ğŸ˜² **Surprise** | 270 (+35%) | 1.45Ã— | 0.95 | Surprise produces rapid, highly-pitched exclamations |
| ğŸ˜¨ **Fear** | 250 (+25%) | 1.18Ã— | 0.75 | Fear produces fast but quiet, slightly higher speech |
| ğŸ¤¢ **Disgust** | 180 (-10%) | 0.88Ã— | 0.80 | Disgust slows speech with a lower, restrained tone |
| ğŸ˜ **Neutral** | 200 (base) | 1.00Ã— | 0.85 | Normal conversational delivery |

### Intensity Scaling Formula

For any parameter `P` with baseline value `B` and emotion delta `D`:

```
P = B + D Ã— intensity
```

Where `intensity âˆˆ [0.0, 1.0]` is derived from the VADER compound score:

```
intensity = min(|compound| Ã— 1.2, 1.0)
```

**Example:** "This is good" (compound=0.44) â†’ intensity=0.53 â†’ moderate adjustment.
"This is the best news ever!" (compound=0.87) â†’ intensity=1.0 â†’ full adjustment.

---

## Design Choices

### Why Dual Emotion Detection?

- **VADER** excels at sentiment intensity scoring with its lexicon+rule approach, providing a reliable compound score for intensity calculation
- **HuggingFace DistilRoBERTa** provides granular 7-class emotion classification that VADER cannot, enabling nuanced voice modulation
- Combining both gives us the best of both worlds: reliable intensity + granular labels

### Why pyttsx3 as Default?

- **Offline** â€” no API keys, no internet required, no costs
- **Cross-platform** â€” works on macOS (NSSpeechSynthesizer), Windows (SAPI5), Linux (espeak)
- **Native parameter control** â€” rate and volume are directly adjustable via the API
- **gTTS alternative** available for higher-quality output when online

### Why Linear Intensity Scaling?

- **Predictable** â€” judges can verify the math
- **Intuitive** â€” stronger emotion â†’ proportionally stronger modulation
- **Avoidance of over-modulation** â€” values are clamped to safe ranges

---

## Project Structure

```
empathy-engine/
â”œâ”€â”€ empathy_engine/              # Core Python package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ emotion_detector.py      # VADER + HuggingFace emotion analysis
â”‚   â”œâ”€â”€ voice_mapper.py          # Emotion â†’ VoiceParams with intensity scaling
â”‚   â”œâ”€â”€ tts_engine.py            # pyttsx3 + gTTS synthesis
â”‚   â””â”€â”€ engine.py                # Main orchestrator pipeline
â”œâ”€â”€ web/                         # Flask web application
â”‚   â”œâ”€â”€ app.py                   # Flask routes & API
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html           # Web UI
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ style.css            # Dark-themed styling
â”œâ”€â”€ output/                      # Generated audio files (auto-created)
â”œâ”€â”€ cli.py                       # CLI entry point
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```

---

## Tech Stack

| Component | Technology |
|-----------|-----------|
| **Language** | Python 3.9+ |
| **Sentiment Analysis** | VADER (vaderSentiment) |
| **Emotion Classification** | HuggingFace Transformers (DistilRoBERTa) |
| **TTS (Offline)** | pyttsx3 |
| **TTS (Online)** | gTTS (Google Text-to-Speech) |
| **Audio Processing** | pydub |
| **Web Framework** | Flask |
| **Frontend** | HTML5, CSS3, Vanilla JavaScript |

---

## License

MIT License â€” see [LICENSE](LICENSE) for details.
